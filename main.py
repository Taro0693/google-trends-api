from flask import Flask, request, jsonify
import time
import random
import logging
import os
import threading
from datetime import datetime, timedelta

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# æ®µéšçš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
PANDAS_AVAILABLE = False
PYTRENDS_AVAILABLE = False

try:
    import pandas as pd
    PANDAS_AVAILABLE = True
    logger.info("âœ… Pandas imported successfully")
except Exception as e:
    logger.error(f"âŒ Pandas import failed: {e}")

try:
    from pytrends.request import TrendReq
    PYTRENDS_AVAILABLE = True
    logger.info("âœ… Pytrends imported successfully")
except Exception as e:
    logger.error(f"âŒ Pytrends import failed: {e}")

# Renderæœ€é©åŒ–: Keep-Aliveæ©Ÿèƒ½
class KeepAlive:
    def __init__(self):
        self.last_request = datetime.now()
        self.is_running = True
        
    def update_last_request(self):
        self.last_request = datetime.now()
        
    def start_keep_alive(self):
        """Keep-Aliveã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹"""
        def keep_alive_worker():
            while self.is_running:
                try:
                    # 10åˆ†é–“éš”ã§pingã‚’é€ä¿¡
                    time.sleep(600)
                    if (datetime.now() - self.last_request).seconds > 600:
                        logger.info("ğŸ”„ Keep-alive ping - server is alive")
                        
                except Exception as e:
                    logger.error(f"Keep-alive error: {e}")
                    
        thread = threading.Thread(target=keep_alive_worker, daemon=True)
        thread.start()
        logger.info("ğŸš€ Keep-alive service started")

# Keep-Aliveã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
keep_alive = KeepAlive()

@app.before_request
def before_request():
    """ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‰å‡¦ç† - Keep-Aliveæ›´æ–°"""
    keep_alive.update_last_request()

@app.route("/")
def home():
    status = {
        "service": "Google Trends API for Smart GAS (Render Optimized)",
        "pandas": "âœ… Available" if PANDAS_AVAILABLE else "âŒ Not Available",
        "pytrends": "âœ… Available" if PYTRENDS_AVAILABLE else "âŒ Not Available",
        "version": "2.1.0 (Render Enhanced)",
        "timestamp": datetime.now().isoformat(),
        "uptime": str(datetime.now() - keep_alive.last_request),
        "environment": "Render" if os.getenv('RENDER') else "Local"
    }
    
    logger.info(f"Home endpoint accessed - Libraries OK: {PANDAS_AVAILABLE and PYTRENDS_AVAILABLE}")
    return jsonify(status)

@app.route("/health")
def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆRenderæœ€é©åŒ–ï¼‰"""
    health_status = {
        "status": "healthy" if PANDAS_AVAILABLE and PYTRENDS_AVAILABLE else "degraded",
        "libraries": {
            "pandas": PANDAS_AVAILABLE,
            "pytrends": PYTRENDS_AVAILABLE
        },
        "timestamp": datetime.now().isoformat(),
        "server_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S UTC"),
        "last_request": keep_alive.last_request.isoformat(),
        "render_optimizations": {
            "keep_alive": True,
            "cold_start_protection": True,
            "enhanced_retry": True
        }
    }
    
    # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªçŠ¶æ…‹ã«ã‚ˆã‚‹é©åˆ‡ãªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰
    status_code = 200 if PANDAS_AVAILABLE and PYTRENDS_AVAILABLE else 503
    
    logger.info(f"Health check - Status: {health_status['status']}")
    return jsonify(health_status), status_code

@app.route("/ping")
def ping():
    """è»½é‡ãªpingã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆKeep-Aliveç”¨ï¼‰"""
    return jsonify({
        "pong": True,
        "timestamp": datetime.now().isoformat()
    })

@app.route("/warmup", methods=["GET", "POST"])
def warmup():
    """ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å°‚ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    logger.info("ğŸ”¥ Warmup endpoint called")
    
    warmup_result = {
        "warmed_up": True,
        "timestamp": datetime.now().isoformat(),
        "libraries_ready": PANDAS_AVAILABLE and PYTRENDS_AVAILABLE,
        "server_ready": True
    }
    
    # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å‹•ä½œãƒ†ã‚¹ãƒˆ
    if PANDAS_AVAILABLE and PYTRENDS_AVAILABLE:
        try:
            # è»½é‡ãªãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            test_trends = TrendReq(hl="ja-JP", tz=540, timeout=(5, 10))
            warmup_result["pytrends_test"] = "âœ… OK"
            logger.info("âœ… Pytrends warmup test successful")
        except Exception as e:
            warmup_result["pytrends_test"] = f"âŒ {str(e)}"
            logger.warning(f"âš ï¸ Pytrends warmup test failed: {e}")
    
    return jsonify(warmup_result)

@app.route("/trend", methods=["POST"])
def trend():
    # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªå¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯
    if not PANDAS_AVAILABLE or not PYTRENDS_AVAILABLE:
        logger.error("âŒ Required libraries not available")
        return jsonify({
            "error": "Required libraries not available",
            "details": {
                "pandas": PANDAS_AVAILABLE,
                "pytrends": PYTRENDS_AVAILABLE
            },
            "solution": "Server is starting up. Please try the /warmup endpoint first."
        }), 503
    
    try:
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã¨æ¤œè¨¼
        data = request.json
        if not data:
            return jsonify({"error": "No JSON data provided"}), 400
        
        validation_result = validate_request(data)
        if not validation_result["valid"]:
            return jsonify({"error": validation_result["message"]}), 400
        
        keywords = data.get("keywords", [])
        timeframe = data.get("timeframe", "today 12-m")
        frequency = data.get("frequency", "weekly")
        geo = data.get("geo", "JP")
        
        logger.info(f"ğŸš€ Processing request: {len(keywords)} keywords, {frequency} frequency, geo: {geo}")
        
        # Renderæœ€é©åŒ–: å‡¦ç†é–‹å§‹ãƒ­ã‚°
        start_time = time.time()
        
        # Google Trendsãƒ‡ãƒ¼ã‚¿å–å¾—
        result = fetch_trends_with_render_optimization(keywords, timeframe, frequency, geo)
        
        # å‡¦ç†æ™‚é–“ãƒ­ã‚°
        processing_time = time.time() - start_time
        logger.info(f"â±ï¸ Processing completed in {processing_time:.2f} seconds")
        
        if "error" in result:
            return jsonify(result), 429 if "rate limit" in result["error"].lower() else 500
        
        # æˆåŠŸæ™‚ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«è¿½åŠ æƒ…å ±
        result["meta"] = {
            "processing_time_seconds": round(processing_time, 2),
            "server_timestamp": datetime.now().isoformat(),
            "keywords_processed": len(keywords),
            "data_points": len(result.get("data", []))
        }
        
        logger.info(f"âœ… Successfully processed {len(keywords)} keywords")
        return jsonify(result)
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"ğŸ’¥ Unexpected error: {error_msg}")
        return jsonify({
            "error": "Internal server error",
            "details": error_msg,
            "timestamp": datetime.now().isoformat()
        }), 500

def validate_request(data):
    """ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®è©³ç´°æ¤œè¨¼ï¼ˆRenderæœ€é©åŒ–ï¼‰"""
    keywords = data.get("keywords", [])
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œè¨¼
    if not keywords:
        return {"valid": False, "message": "Keywords are required"}
    
    if not isinstance(keywords, list):
        return {"valid": False, "message": "Keywords must be a list"}
    
    if len(keywords) > 4:
        return {"valid": False, "message": "Maximum 4 keywords allowed (Google Trends API limitation)"}
    
    # ç©ºã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
    valid_keywords = [k for k in keywords if k and str(k).strip()]
    if len(valid_keywords) != len(keywords):
        return {"valid": False, "message": "Empty keywords are not allowed"}
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é•·ãƒã‚§ãƒƒã‚¯ï¼ˆRenderæœ€é©åŒ–ï¼‰
    for keyword in keywords:
        if len(str(keyword).strip()) > 100:
            return {"valid": False, "message": "Keywords must be less than 100 characters"}
    
    # æœŸé–“æ¤œè¨¼
    frequency = data.get("frequency", "weekly").lower()
    valid_frequencies = ["daily", "weekly", "monthly"]
    if frequency not in valid_frequencies:
        return {"valid": False, "message": f"Frequency must be one of: {valid_frequencies}"}
    
    # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ æ¤œè¨¼
    timeframe = data.get("timeframe", "")
    if timeframe and not validate_timeframe(timeframe, frequency):
        return {"valid": False, "message": "Invalid timeframe for specified frequency"}
    
    return {"valid": True}

def validate_timeframe(timeframe, frequency):
    """ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã¨æœŸé–“ã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
    try:
        if " " in timeframe:
            start_str, end_str = timeframe.split(" ", 1)
            start_date = datetime.strptime(start_str, "%Y-%m-%d")
            end_date = datetime.strptime(end_str, "%Y-%m-%d")
            
            days_diff = (end_date - start_date).days
            
            # Google Trendsã®åˆ¶ç´„ã‚’ãƒã‚§ãƒƒã‚¯
            if frequency == "daily" and days_diff > 270:
                return False
            elif frequency == "weekly" and days_diff < 7:
                return False
            elif frequency == "monthly" and days_diff < 30:
                return False
                
        return True
    except:
        return True

def fetch_trends_with_render_optimization(keywords, timeframe, frequency, geo):
    """Renderæœ€é©åŒ–ç‰ˆãƒ‡ãƒ¼ã‚¿å–å¾—"""
    max_retries = 4  # Renderç”¨ã«å¢—åŠ 
    base_delay = 8   # Renderç”¨ã«å»¶é•·
    
    for attempt in range(max_retries):
        try:
            logger.info(f"ğŸ”„ Attempt {attempt + 1}/{max_retries} for keywords: {keywords}")
            
            # è©¦è¡Œé–“ã®å¾…æ©Ÿï¼ˆRenderæœ€é©åŒ–ï¼‰
            if attempt > 0:
                wait_time = base_delay * (2 ** (attempt - 1)) + random.uniform(3, 12)
                logger.info(f"â³ Waiting {wait_time:.1f} seconds before retry...")
                time.sleep(wait_time)
            
            # åˆæœŸãƒ©ãƒ³ãƒ€ãƒ é…å»¶ï¼ˆCold startå¯¾ç­–ï¼‰
            initial_delay = random.uniform(2, 6) if attempt == 0 else random.uniform(1, 3)
            logger.info(f"â³ Initial delay: {initial_delay:.1f} seconds")
            time.sleep(initial_delay)
            
            # pytrends ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆï¼ˆRenderæœ€é©åŒ–ï¼‰
            pytrends = TrendReq(
                hl="ja-JP", 
                tz=540,
                timeout=(15, 30),  # Renderç”¨ã«ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå»¶é•·
                retries=3,         # å†…éƒ¨ãƒªãƒˆãƒ©ã‚¤å¢—åŠ 
                backoff_factor=0.2 # ãƒãƒƒã‚¯ã‚ªãƒ•ä¿‚æ•°èª¿æ•´
            )
            
            # ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰æ§‹ç¯‰
            build_payload_safely(pytrends, keywords, timeframe, geo)
            
            # ãƒ‡ãƒ¼ã‚¿å–å¾—
            logger.info("ğŸ“Š Fetching data from Google Trends...")
            df = pytrends.interest_over_time()
            
            if df.empty:
                if attempt == max_retries - 1:
                    logger.warning("ğŸ“­ No data available after all retries")
                    return {"error": "No data available from Google Trends after all retries"}
                logger.warning(f"ğŸ“­ Empty data on attempt {attempt + 1}, retrying...")
                continue
            
            # ãƒ‡ãƒ¼ã‚¿å‡¦ç†
            logger.info("ğŸ”§ Processing data...")
            processed_data = process_trends_dataframe(df, frequency)
            
            logger.info(f"âœ… Success on attempt {attempt + 1}")
            return {"data": processed_data}
            
        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ Attempt {attempt + 1} failed: {error_msg}")
            
            # Rate limitã‚¨ãƒ©ãƒ¼ã®ç‰¹åˆ¥å‡¦ç†ï¼ˆRenderæœ€é©åŒ–ï¼‰
            if any(keyword in error_msg.lower() for keyword in ["429", "rate limit", "too many requests"]):
                if attempt < max_retries - 1:
                    long_wait = 90 + random.uniform(30, 60)  # 2-2.5åˆ†
                    logger.info(f"ğŸš« Rate limit detected, waiting {long_wait:.1f} seconds...")
                    time.sleep(long_wait)
                    continue
                else:
                    return {"error": "Rate limit exceeded. Please try again later.", "retry_after": 300}
            
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ã®å‡¦ç†
            if "timeout" in error_msg.lower():
                if attempt < max_retries - 1:
                    timeout_wait = 30 + random.uniform(10, 30)
                    logger.info(f"â° Timeout detected, waiting {timeout_wait:.1f} seconds...")
                    time.sleep(timeout_wait)
                    continue
            
            # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼
            if attempt == max_retries - 1:
                return {"error": f"Failed after {max_retries} attempts: {error_msg}"}
    
    return {"error": "Unknown error occurred"}

def build_payload_safely(pytrends, keywords, timeframe, geo):
    """å®‰å…¨ãªãƒšã‚¤ãƒ­ãƒ¼ãƒ‰æ§‹ç¯‰ï¼ˆRenderæœ€é©åŒ–ï¼‰"""
    try:
        logger.info(f"ğŸ”§ Building payload for keywords: {keywords}")
        
        # åŸºæœ¬çš„ãªãƒšã‚¤ãƒ­ãƒ¼ãƒ‰æ§‹ç¯‰
        if geo and geo.strip() and geo.upper() != "NONE":
            pytrends.build_payload(
                kw_list=keywords,
                timeframe=timeframe,
                geo=geo.upper()
            )
        else:
            pytrends.build_payload(
                kw_list=keywords,
                timeframe=timeframe
            )
            
        logger.info("âœ… Payload built successfully")
        
    except Exception as e:
        logger.error(f"âŒ Payload build error: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚ˆã‚ŠåŸºæœ¬çš„ãªãƒšã‚¤ãƒ­ãƒ¼ãƒ‰
        try:
            pytrends.build_payload(kw_list=keywords)
            logger.info("âœ… Fallback payload built")
        except Exception as fallback_error:
            logger.error(f"âŒ Fallback payload failed: {fallback_error}")
            raise e

def process_trends_dataframe(df, frequency):
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ï¼ˆRenderæœ€é©åŒ–ç‰ˆï¼‰"""
    try:
        logger.info(f"ğŸ“Š Processing DataFrame: {df.shape}")
        
        # isPartialåˆ—ã®å‰Šé™¤
        if 'isPartial' in df.columns:
            df = df.drop(columns=['isPartial'])
            logger.info("ğŸ—‘ï¸ Removed isPartial column")
        
        # æœŸé–“å¤‰æ›
        if frequency == "daily":
            df = convert_to_daily_safe(df)
        elif frequency == "monthly":
            df = convert_to_monthly_safe(df)
        # weeklyã¯ãã®ã¾ã¾ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åˆ—ã«å¤‰æ›
        df_result = df.reset_index()
        
        # æ—¥ä»˜åˆ—ã®å‡¦ç†
        date_column = find_date_column(df_result)
        if date_column and date_column != 'date':
            df_result = df_result.rename(columns={date_column: 'date'})
            logger.info(f"ğŸ“… Renamed date column: {date_column} -> date")
        
        # æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        if 'date' in df_result.columns:
            df_result['date'] = format_dates_safely(df_result['date'])
        
        # NaNå€¤ã‚’0ã§ç½®æ›
        df_result = df_result.fillna(0)
        
        # æ•´æ•°å‹ã«å¤‰æ›ï¼ˆtrendå€¤ï¼‰
        for col in df_result.columns:
            if col != 'date':
                df_result[col] = df_result[col].astype(int)
        
        # è¾æ›¸å½¢å¼ã§è¿”å´
        records = df_result.to_dict(orient="records")
        
        logger.info(f"âœ… Processed {len(records)} records with {len(df_result.columns)} columns")
        return records
        
    except Exception as e:
        logger.error(f"âŒ DataFrame processing error: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€å°é™ã®å‡¦ç†
        try:
            df_simple = df.reset_index().fillna(0)
            simple_records = df_simple.to_dict(orient="records")
            logger.info(f"âš ï¸ Fallback processing: {len(simple_records)} records")
            return simple_records
        except:
            raise Exception(f"Data processing failed completely: {e}")

def convert_to_daily_safe(df):
    """å®‰å…¨ãªæ—¥æ¬¡å¤‰æ›"""
    try:
        if not isinstance(df.index, pd.DatetimeIndex):
            return df
        
        start_date = df.index.min()
        end_date = df.index.max()
        daily_index = pd.date_range(start=start_date, end=end_date, freq='D')
        
        df_reindexed = df.reindex(df.index.union(daily_index))
        df_interpolated = df_reindexed.interpolate(method='linear')
        df_daily = df_interpolated.reindex(daily_index)
        
        logger.info(f"ğŸ“… Converted to daily: {len(df_daily)} days")
        return df_daily
        
    except Exception as e:
        logger.warning(f"âš ï¸ Daily conversion failed: {e}, returning original data")
        return df

def convert_to_monthly_safe(df):
    """å®‰å…¨ãªæœˆæ¬¡å¤‰æ›"""
    try:
        if not isinstance(df.index, pd.DatetimeIndex):
            return df
        
        df_monthly = df.resample('M').mean()
        df_monthly.index = df_monthly.index.to_period('M').to_timestamp()
        
        logger.info(f"ğŸ“… Converted to monthly: {len(df_monthly)} months")
        return df_monthly
        
    except Exception as e:
        logger.warning(f"âš ï¸ Monthly conversion failed: {e}, returning original data")
        return df

def find_date_column(df):
    """æ—¥ä»˜åˆ—ã‚’ç‰¹å®š"""
    for col in df.columns:
        if any(word in col.lower() for word in ['date', 'time', 'index']):
            return col
        
        try:
            if pd.api.types.is_datetime64_any_dtype(df[col]):
                return col
        except:
            continue
    
    return None

def format_dates_safely(date_series):
    """å®‰å…¨ãªæ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    try:
        date_series = pd.to_datetime(date_series)
        return date_series.dt.strftime('%Y-%m-%d')
    except Exception as e:
        logger.warning(f"âš ï¸ Date formatting failed: {e}, returning original")
        return date_series

# Renderã«æœ€é©åŒ–ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
@app.errorhandler(404)
def not_found(error):
    return jsonify({
        "error": "Endpoint not found",
        "available_endpoints": ["/", "/health", "/ping", "/warmup", "/trend"],
        "timestamp": datetime.now().isoformat()
    }), 404

@app.errorhandler(405)
def method_not_allowed(error):
    return jsonify({
        "error": "Method not allowed",
        "hint": "Use POST for /trend endpoint",
        "timestamp": datetime.now().isoformat()
    }), 405

@app.errorhandler(500)
def internal_error(error):
    logger.error(f"ğŸ’¥ Internal server error: {error}")
    return jsonify({
        "error": "Internal server error",
        "libraries_status": {
            "pandas": PANDAS_AVAILABLE,
            "pytrends": PYTRENDS_AVAILABLE
        },
        "timestamp": datetime.now().isoformat()
    }), 500

if __name__ == "__main__":
    logger.info("ğŸš€ Starting Google Trends API server (Render optimized version)...")
    
    # Keep-Aliveã‚µãƒ¼ãƒ“ã‚¹é–‹å§‹
    keep_alive.start_keep_alive()
    
    # Renderã®å ´åˆã¯ãƒãƒ¼ãƒˆè¨­å®š
    port = int(os.environ.get("PORT", 10000))
    
    logger.info(f"ğŸŒ Server starting on port {port}")
    app.run(host="0.0.0.0", port=port, debug=False)
